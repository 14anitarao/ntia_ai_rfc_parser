
                      In the early days of AI development the big rule was to explain the logic behind the answer.  Nothing in AI can be done that a human can do since humans have to program AI so the audits should be similar to audits we can use for any system.  Being able to view the source data behind the answer is key to understanding the reasoning behind any AI system output is key to understanding if the programming is honest and fair.  One of the things I like about some of the current AI systems is they are evenly balanced and neutral, which is at the least refreshing.  Most human interactions these days seem to be either agreement or nasty disagreement.  Neither of these are as useful as a balanced response with both pros and cons.  Being able to keep digging down into the next level of details into the data behind the response from any system tells us how good the information is.
                    